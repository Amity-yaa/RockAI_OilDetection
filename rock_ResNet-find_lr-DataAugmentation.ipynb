{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ResNet-50识别岩石样本</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\envs\\keras\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 导包\n",
    "#import tensorflow.compat.v1 as tf\n",
    "my_seed = 520\n",
    "# 导包\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "\n",
    "# 设置随机种子，保证可复现, 随机种子的设置要在任何一次使用到随机数前设置，因此通常在刚导入完所有包后立即设置。提示：后续的解决样本不平衡过程。\n",
    "np.random.seed(my_seed)\n",
    "random.seed(my_seed)\n",
    "ia.seed(my_seed)\n",
    "# tf.random.set_seed(my_seed)\n",
    "\n",
    "import keras as K\n",
    "from keras import backend\n",
    "import pandas as pd\n",
    "from keras import models,layers \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt \n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "# from numba import cuda\n",
    "import cv2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\envs\\keras\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers =  177\n"
     ]
    }
   ],
   "source": [
    "# 引入ResNet网络\n",
    "\n",
    "num_classes = 7  # rock为7类\n",
    "def ResNet50Model():\n",
    "    model = K.applications.ResNet50(include_top=False, weights=\"imagenet\", input_shape =(224, 224, 3))\n",
    "    \n",
    "    new_output = K.layers.GlobalAveragePooling2D()(model.output)\n",
    "    new_output = K.layers.Dense(num_classes, activation = 'softmax')(new_output)\n",
    "    \n",
    "    model = K.engine.training.Model(model.inputs, new_output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet50Model()\n",
    "print(\"num_layers = \", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1   trainable =  True\n",
      "conv1_pad   trainable =  True\n",
      "conv1   trainable =  True\n",
      "bn_conv1   trainable =  True\n",
      "activation_1   trainable =  True\n",
      "pool1_pad   trainable =  True\n",
      "max_pooling2d_1   trainable =  True\n",
      "res2a_branch2a   trainable =  True\n",
      "bn2a_branch2a   trainable =  True\n",
      "activation_2   trainable =  True\n",
      "res2a_branch2b   trainable =  True\n",
      "bn2a_branch2b   trainable =  True\n",
      "activation_3   trainable =  True\n",
      "res2a_branch2c   trainable =  True\n",
      "res2a_branch1   trainable =  True\n",
      "bn2a_branch2c   trainable =  True\n",
      "bn2a_branch1   trainable =  True\n",
      "add_1   trainable =  True\n",
      "activation_4   trainable =  True\n",
      "res2b_branch2a   trainable =  True\n",
      "bn2b_branch2a   trainable =  True\n",
      "activation_5   trainable =  True\n",
      "res2b_branch2b   trainable =  True\n",
      "bn2b_branch2b   trainable =  True\n",
      "activation_6   trainable =  True\n",
      "res2b_branch2c   trainable =  True\n",
      "bn2b_branch2c   trainable =  True\n",
      "add_2   trainable =  True\n",
      "activation_7   trainable =  True\n",
      "res2c_branch2a   trainable =  True\n",
      "bn2c_branch2a   trainable =  True\n",
      "activation_8   trainable =  True\n",
      "res2c_branch2b   trainable =  True\n",
      "bn2c_branch2b   trainable =  True\n",
      "activation_9   trainable =  True\n",
      "res2c_branch2c   trainable =  True\n",
      "bn2c_branch2c   trainable =  True\n",
      "add_3   trainable =  True\n",
      "activation_10   trainable =  True\n",
      "res3a_branch2a   trainable =  True\n",
      "bn3a_branch2a   trainable =  True\n",
      "activation_11   trainable =  True\n",
      "res3a_branch2b   trainable =  True\n",
      "bn3a_branch2b   trainable =  True\n",
      "activation_12   trainable =  True\n",
      "res3a_branch2c   trainable =  True\n",
      "res3a_branch1   trainable =  True\n",
      "bn3a_branch2c   trainable =  True\n",
      "bn3a_branch1   trainable =  True\n",
      "add_4   trainable =  True\n",
      "activation_13   trainable =  True\n",
      "res3b_branch2a   trainable =  True\n",
      "bn3b_branch2a   trainable =  True\n",
      "activation_14   trainable =  True\n",
      "res3b_branch2b   trainable =  True\n",
      "bn3b_branch2b   trainable =  True\n",
      "activation_15   trainable =  True\n",
      "res3b_branch2c   trainable =  True\n",
      "bn3b_branch2c   trainable =  True\n",
      "add_5   trainable =  True\n",
      "activation_16   trainable =  True\n",
      "res3c_branch2a   trainable =  True\n",
      "bn3c_branch2a   trainable =  True\n",
      "activation_17   trainable =  True\n",
      "res3c_branch2b   trainable =  True\n",
      "bn3c_branch2b   trainable =  True\n",
      "activation_18   trainable =  True\n",
      "res3c_branch2c   trainable =  True\n",
      "bn3c_branch2c   trainable =  True\n",
      "add_6   trainable =  True\n",
      "activation_19   trainable =  True\n",
      "res3d_branch2a   trainable =  True\n",
      "bn3d_branch2a   trainable =  True\n",
      "activation_20   trainable =  True\n",
      "res3d_branch2b   trainable =  True\n",
      "bn3d_branch2b   trainable =  True\n",
      "activation_21   trainable =  True\n",
      "res3d_branch2c   trainable =  True\n",
      "bn3d_branch2c   trainable =  True\n",
      "add_7   trainable =  True\n",
      "activation_22   trainable =  True\n",
      "res4a_branch2a   trainable =  True\n",
      "bn4a_branch2a   trainable =  True\n",
      "activation_23   trainable =  True\n",
      "res4a_branch2b   trainable =  True\n",
      "bn4a_branch2b   trainable =  True\n",
      "activation_24   trainable =  True\n",
      "res4a_branch2c   trainable =  True\n",
      "res4a_branch1   trainable =  True\n",
      "bn4a_branch2c   trainable =  True\n",
      "bn4a_branch1   trainable =  True\n",
      "add_8   trainable =  True\n",
      "activation_25   trainable =  True\n",
      "res4b_branch2a   trainable =  True\n",
      "bn4b_branch2a   trainable =  True\n",
      "activation_26   trainable =  True\n",
      "res4b_branch2b   trainable =  True\n",
      "bn4b_branch2b   trainable =  True\n",
      "activation_27   trainable =  True\n",
      "res4b_branch2c   trainable =  True\n",
      "bn4b_branch2c   trainable =  True\n",
      "add_9   trainable =  True\n",
      "activation_28   trainable =  True\n",
      "res4c_branch2a   trainable =  True\n",
      "bn4c_branch2a   trainable =  True\n",
      "activation_29   trainable =  True\n",
      "res4c_branch2b   trainable =  True\n",
      "bn4c_branch2b   trainable =  True\n",
      "activation_30   trainable =  True\n",
      "res4c_branch2c   trainable =  True\n",
      "bn4c_branch2c   trainable =  True\n",
      "add_10   trainable =  True\n",
      "activation_31   trainable =  True\n",
      "res4d_branch2a   trainable =  True\n",
      "bn4d_branch2a   trainable =  True\n",
      "activation_32   trainable =  True\n",
      "res4d_branch2b   trainable =  True\n",
      "bn4d_branch2b   trainable =  True\n",
      "activation_33   trainable =  True\n",
      "res4d_branch2c   trainable =  True\n",
      "bn4d_branch2c   trainable =  True\n",
      "add_11   trainable =  True\n",
      "activation_34   trainable =  True\n",
      "res4e_branch2a   trainable =  True\n",
      "bn4e_branch2a   trainable =  True\n",
      "activation_35   trainable =  True\n",
      "res4e_branch2b   trainable =  True\n",
      "bn4e_branch2b   trainable =  True\n",
      "activation_36   trainable =  True\n",
      "res4e_branch2c   trainable =  True\n",
      "bn4e_branch2c   trainable =  True\n",
      "add_12   trainable =  True\n",
      "activation_37   trainable =  True\n",
      "res4f_branch2a   trainable =  True\n",
      "bn4f_branch2a   trainable =  True\n",
      "activation_38   trainable =  True\n",
      "res4f_branch2b   trainable =  True\n",
      "bn4f_branch2b   trainable =  True\n",
      "activation_39   trainable =  True\n",
      "res4f_branch2c   trainable =  True\n",
      "bn4f_branch2c   trainable =  True\n",
      "add_13   trainable =  True\n",
      "activation_40   trainable =  True\n",
      "res5a_branch2a   trainable =  True\n",
      "bn5a_branch2a   trainable =  True\n",
      "activation_41   trainable =  True\n",
      "res5a_branch2b   trainable =  True\n",
      "bn5a_branch2b   trainable =  True\n",
      "activation_42   trainable =  True\n",
      "res5a_branch2c   trainable =  True\n",
      "res5a_branch1   trainable =  True\n",
      "bn5a_branch2c   trainable =  True\n",
      "bn5a_branch1   trainable =  True\n",
      "add_14   trainable =  True\n",
      "activation_43   trainable =  True\n",
      "res5b_branch2a   trainable =  True\n",
      "bn5b_branch2a   trainable =  True\n",
      "activation_44   trainable =  True\n",
      "res5b_branch2b   trainable =  True\n",
      "bn5b_branch2b   trainable =  True\n",
      "activation_45   trainable =  True\n",
      "res5b_branch2c   trainable =  True\n",
      "bn5b_branch2c   trainable =  True\n",
      "add_15   trainable =  True\n",
      "activation_46   trainable =  True\n",
      "res5c_branch2a   trainable =  True\n",
      "bn5c_branch2a   trainable =  True\n",
      "activation_47   trainable =  True\n",
      "res5c_branch2b   trainable =  True\n",
      "bn5c_branch2b   trainable =  True\n",
      "activation_48   trainable =  True\n",
      "res5c_branch2c   trainable =  True\n",
      "bn5c_branch2c   trainable =  True\n",
      "add_16   trainable =  True\n",
      "activation_49   trainable =  True\n",
      "global_average_pooling2d_1   trainable =  True\n",
      "dense_1   trainable =  True\n"
     ]
    }
   ],
   "source": [
    "# 冻结前168层，但不冻结其间的Batch Normalization\n",
    "num_feerezed_layer = 168\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "    if isinstance(layer, K.layers.BatchNormalization):\n",
    "        layer.momentum = 0.9    # 认为动量为0.9时能更好的适应新的数据集\n",
    "\n",
    "for layer in model.layers[:num_feerezed_layer]:\n",
    "\n",
    "    if not isinstance(layer, K.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# 检查可训练层冻结是否正确\n",
    "for layer in model.layers:\n",
    "    print(layer.name, \" \", \"trainable = \", layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入训练数据\n",
    "rock_path = './train_1'\n",
    "label_path = './label_new.csv'\n",
    "label = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 85], [1, 18], [2, 30], [3, 75], [4, 46], [5, 40], [6, 21]]\n",
      "样本数最多的是 85\n"
     ]
    }
   ],
   "source": [
    "#计算最多的样本数\n",
    "num_cls = []\n",
    "for cls in set(label['类别标签']):\n",
    "    num_cls.append([cls,len(label[label['类别标签']==cls])])\n",
    "max_num_cls = max([i[1] for i in num_cls])\n",
    "print(num_cls)\n",
    "print('样本数最多的是',max_num_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本编号</th>\n",
       "      <th>样本类别</th>\n",
       "      <th>类别标签</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "      <td>灰黑色泥岩</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>灰色泥质粉砂岩</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>灰色泥质粉砂岩</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>黑色煤</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>灰黑色泥岩</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>153</td>\n",
       "      <td>深灰色粉砂质泥岩</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>179</td>\n",
       "      <td>灰黑色泥岩</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>179</td>\n",
       "      <td>灰黑色泥岩</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>67</td>\n",
       "      <td>深灰色泥岩</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>16</td>\n",
       "      <td>浅灰色细砂岩</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     样本编号      样本类别  类别标签\n",
       "0     257     灰黑色泥岩     2\n",
       "1      22   灰色泥质粉砂岩     4\n",
       "2      22   灰色泥质粉砂岩     4\n",
       "3      83       黑色煤     6\n",
       "4      21     灰黑色泥岩     2\n",
       "..    ...       ...   ...\n",
       "590   153  深灰色粉砂质泥岩     5\n",
       "591   179     灰黑色泥岩     2\n",
       "592   179     灰黑色泥岩     2\n",
       "593    67     深灰色泥岩     3\n",
       "594    16    浅灰色细砂岩     0\n",
       "\n",
       "[595 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最简单的解决样本不平衡方法一：复制小比例样本\n",
    "for cls in range(len(num_cls)):\n",
    "    label_cls = label[label['类别标签']==cls]\n",
    "    residual_num = max_num_cls-len(label_cls) # 计算要补充的数量\n",
    "    residual_index = np.random.choice(range(len(label_cls)),residual_num)\n",
    "    label_residual = label_cls.iloc[residual_index]\n",
    "    label = pd.concat([label,label_residual],ignore_index = True)\n",
    "random_index = np.arange(len(label))\n",
    "random.shuffle(random_index)\n",
    "label = label.iloc[random_index]\n",
    "label.index = range(len(label))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 ，344 ， 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pathes = ['{}-1.bmp'.format(i) if i<=320 else '{}-1.jpg'.format(i) for i in label['样本编号']  ]\n",
    "img_pathes = [os.path.join(rock_path,i) for i in img_pathes]# 补全路径,全部图片的路径\n",
    "label = label['类别标签']\n",
    "label = list(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割训练集和测试集\n",
    "val_ratio = 0.2\n",
    "x_train, x_val, y_train, y_val = train_test_split(img_pathes, label, test_size=val_ratio, \n",
    "                                                  random_state=42, shuffle=True, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化，并且把输入的图片从RGB模式改为BGR模式\n",
    "def imgsub(img):\n",
    "    img_res = np.zeros(img.shape)          # R G B\n",
    "    img_res[:,:,0] = img[:,:,2]            # B = B - B\n",
    "    img_res[:,:,1] = img[:,:,1]            # G = G - G\n",
    "    img_res[:,:,2] = img[:,:,0]            # R = R - R\n",
    "    return img_res  # B G R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\envs\\keras\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # 0.5的概率水平翻转\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Crop(percent=(0, 0.2)), # random crops\n",
    "    iaa.ContrastNormalization((0.75, 1.25)),\n",
    "    iaa.Multiply((0.75, 1.5)),\n",
    "    # 对每张图片进行仿射变换，包括缩放、平移、旋转、修剪等\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-180, 180),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True) # 随机应用以上的图片增强方法\n",
    "\n",
    "# 定义生成器，用于训练时batch的生成（小批量生成可以避免内存不够）\n",
    "def Generator(img_set,labels,batch_size,return_names = False):\n",
    "    while True:\n",
    "        img_batch = []\n",
    "        label_batch = []\n",
    "        path_batch = []\n",
    "        for i in range(len(img_set)):\n",
    "            img_path = img_set[i]\n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((224,224))\n",
    "            img = np.asarray(img)\n",
    "            img_batch.append(img)\n",
    "\n",
    "            label = labels[i]\n",
    "            label_batch.append(label)\n",
    "            path_batch.append(img_path)\n",
    "            if (i+1)%batch_size==0 or (i+1) == len(img_set):# 凑够batch_size张图片的矩阵\n",
    "                img_batch = np.array(img_batch) # 拼成一个大矩阵，用于训练\n",
    "                img_batch = seq.augment_images(img_batch.astype(np.uint8)).astype(np.float64)\n",
    "                for i in range(img_batch.shape[0]):\n",
    "                    img_batch[i] = imgsub(img_batch[i])\n",
    "                label_batch = np.array(label_batch)\n",
    "                label_batch = K.utils.to_categorical(label_batch, num_classes=7)\n",
    "                if not return_names:\n",
    "                    yield img_batch,label_batch#,img_batch_before_aug\n",
    "                else:\n",
    "                    yield img_batch,label_batch,path_batch\n",
    "                img_batch = []\n",
    "                label_batch = []\n",
    "                path_batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找最优学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aae03a5646a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# if not os.path.exists('Best_rock_Model(ResNet).h5'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlr_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet50Model' is not defined"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists('Best_rock_Model(ResNet).h5'):\n",
    "if True:\n",
    "    model = ResNet50Model()\n",
    "\n",
    "    lr_begin = 1e-12\n",
    "    lr_end = 0.1\n",
    "\n",
    "    batch_size = 5\n",
    "    train_g = Generator(x_train, y_train, batch_size)\n",
    "    batch_num = len(x_train)//batch_size+1 # 一个epoch所含有的batch数量\n",
    "\n",
    "    lr = lr_begin\n",
    "    lr_multi = (lr_end/lr_begin)**(1/batch_num)\n",
    "    lr_all = []\n",
    "    loss_all = []\n",
    "    acc_all = []\n",
    "\n",
    "    optim = K.optimizers.Adamax(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim,\n",
    "                      metrics=['accuracy'])\n",
    "    cnt = 0\n",
    "    for batch_data, batch_y in train_g:\n",
    "        cnt+=1\n",
    "        backend.set_value(model.optimizer.lr, lr)\n",
    "        loss,acc = model.train_on_batch(batch_data,batch_y)\n",
    "        lr_all.append(lr)\n",
    "        loss_all.append(loss)\n",
    "        acc_all.append(acc)\n",
    "        lr = lr*lr_multi  \n",
    "\n",
    "        if cnt == batch_num:\n",
    "            break\n",
    "\n",
    "    lr_all = np.array(lr_all)\n",
    "    lr_best = lr_all[np.argmin(loss_all)]\n",
    "    print('最优学习率为:',lr_best)\n",
    "    plt.plot(np.log10(lr_all),loss_all)\n",
    "    plt.xticks(np.log10([ 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2,1e-1]), [ 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2,1e-1])\n",
    "    plt.xlim(np.log10(1e-10),np.log10(1e-2))\n",
    "    plt.ylim(0,3)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('learning rate')\n",
    "    plt.savefig('find_lr_520.png',dpi  =100 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\envs\\keras\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "0 1e-04\n",
      "95/95 [==============================] - 30s 318ms/step - loss: 1.5476 - accuracy: 0.4147 - val_loss: 1.7566 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43478, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 2/50\n",
      "1 1e-04\n",
      "95/95 [==============================] - 20s 209ms/step - loss: 1.2507 - accuracy: 0.5350 - val_loss: 1.2077 - val_accuracy: 0.5702\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.43478 to 0.57018, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 3/50\n",
      "2 1e-04\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 1.1371 - accuracy: 0.5796 - val_loss: 3.0130 - val_accuracy: 0.6053\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57018 to 0.60526, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 4/50\n",
      "3 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 1.0529 - accuracy: 0.6093 - val_loss: 0.9955 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.60526 to 0.61404, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 5/50\n",
      "4 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9688 - accuracy: 0.6561 - val_loss: 0.0939 - val_accuracy: 0.5702\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61404\n",
      "Epoch 6/50\n",
      "5 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9885 - accuracy: 0.6412 - val_loss: 2.4380 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.61404 to 0.65789, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 7/50\n",
      "6 1e-06\n",
      "95/95 [==============================] - 20s 208ms/step - loss: 1.0105 - accuracy: 0.6306 - val_loss: 1.0665 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65789\n",
      "Epoch 8/50\n",
      "7 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9267 - accuracy: 0.6645 - val_loss: 0.4273 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65789\n",
      "Epoch 9/50\n",
      "8 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9571 - accuracy: 0.6688 - val_loss: 0.6324 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65789\n",
      "Epoch 10/50\n",
      "9 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9060 - accuracy: 0.6667 - val_loss: 1.0777 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65789\n",
      "Epoch 11/50\n",
      "10 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8996 - accuracy: 0.6667 - val_loss: 3.3034 - val_accuracy: 0.5965\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65789\n",
      "Epoch 12/50\n",
      "11 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9056 - accuracy: 0.6730 - val_loss: 2.1621 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65789\n",
      "Epoch 13/50\n",
      "12 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9197 - accuracy: 0.6645 - val_loss: 1.6921 - val_accuracy: 0.6053\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65789\n",
      "Epoch 14/50\n",
      "13 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9086 - accuracy: 0.6539 - val_loss: 0.4311 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65789\n",
      "Epoch 15/50\n",
      "14 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.9203 - accuracy: 0.6561 - val_loss: 1.0016 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65789\n",
      "Epoch 16/50\n",
      "15 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8994 - accuracy: 0.6730 - val_loss: 0.4766 - val_accuracy: 0.5702\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65789\n",
      "Epoch 17/50\n",
      "16 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8841 - accuracy: 0.6921 - val_loss: 0.5485 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65789\n",
      "Epoch 18/50\n",
      "17 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8445 - accuracy: 0.6985 - val_loss: 1.8425 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65789\n",
      "Epoch 19/50\n",
      "18 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8660 - accuracy: 0.6815 - val_loss: 1.6740 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65789\n",
      "Epoch 20/50\n",
      "19 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8682 - accuracy: 0.6900 - val_loss: 3.1128 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65789\n",
      "Epoch 21/50\n",
      "20 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8685 - accuracy: 0.6815 - val_loss: 0.4495 - val_accuracy: 0.6053\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.65789\n",
      "Epoch 22/50\n",
      "21 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8458 - accuracy: 0.6964 - val_loss: 1.1511 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.65789\n",
      "Epoch 23/50\n",
      "22 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8499 - accuracy: 0.6964 - val_loss: 0.3735 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65789\n",
      "Epoch 24/50\n",
      "23 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8522 - accuracy: 0.6879 - val_loss: 1.8851 - val_accuracy: 0.6404\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65789\n",
      "Epoch 25/50\n",
      "24 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8129 - accuracy: 0.7197 - val_loss: 1.7702 - val_accuracy: 0.5826\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65789\n",
      "Epoch 26/50\n",
      "25 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8554 - accuracy: 0.6773 - val_loss: 0.7571 - val_accuracy: 0.5965\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65789\n",
      "Epoch 27/50\n",
      "26 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8547 - accuracy: 0.6815 - val_loss: 2.0543 - val_accuracy: 0.5789\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65789\n",
      "Epoch 28/50\n",
      "27 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8485 - accuracy: 0.7113 - val_loss: 2.2328 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.65789\n",
      "Epoch 29/50\n",
      "28 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8067 - accuracy: 0.7049 - val_loss: 0.6445 - val_accuracy: 0.6404\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.65789\n",
      "Epoch 30/50\n",
      "29 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7825 - accuracy: 0.7155 - val_loss: 2.0865 - val_accuracy: 0.5965\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.65789\n",
      "Epoch 31/50\n",
      "30 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7950 - accuracy: 0.7028 - val_loss: 1.7441 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.65789\n",
      "Epoch 32/50\n",
      "31 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7860 - accuracy: 0.7176 - val_loss: 0.3930 - val_accuracy: 0.5702\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.65789\n",
      "Epoch 33/50\n",
      "32 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8072 - accuracy: 0.6985 - val_loss: 0.3418 - val_accuracy: 0.6404\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65789\n",
      "Epoch 34/50\n",
      "33 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8364 - accuracy: 0.7197 - val_loss: 1.4556 - val_accuracy: 0.5789\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.65789\n",
      "Epoch 35/50\n",
      "34 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.8079 - accuracy: 0.7091 - val_loss: 2.1563 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65789\n",
      "Epoch 36/50\n",
      "35 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7789 - accuracy: 0.7219 - val_loss: 1.5119 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.65789 to 0.66667, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 37/50\n",
      "36 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7617 - accuracy: 0.7240 - val_loss: 1.5162 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66667\n",
      "Epoch 38/50\n",
      "37 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7616 - accuracy: 0.7282 - val_loss: 0.5203 - val_accuracy: 0.6491\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66667\n",
      "Epoch 39/50\n",
      "38 1e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 20s 206ms/step - loss: 0.8115 - accuracy: 0.7219 - val_loss: 0.2592 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66667\n",
      "Epoch 40/50\n",
      "39 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7928 - accuracy: 0.7197 - val_loss: 0.6019 - val_accuracy: 0.5614\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66667\n",
      "Epoch 41/50\n",
      "40 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7989 - accuracy: 0.7070 - val_loss: 0.7618 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66667\n",
      "Epoch 42/50\n",
      "41 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7571 - accuracy: 0.7091 - val_loss: 1.7426 - val_accuracy: 0.6491\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66667\n",
      "Epoch 43/50\n",
      "42 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7579 - accuracy: 0.7219 - val_loss: 1.3351 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66667\n",
      "Epoch 44/50\n",
      "43 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7510 - accuracy: 0.7410 - val_loss: 2.3800 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66667\n",
      "Epoch 45/50\n",
      "44 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7507 - accuracy: 0.7410 - val_loss: 0.1985 - val_accuracy: 0.6754\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.66667 to 0.67544, saving model to Best_rock_Model(ResNet).h5\n",
      "Epoch 46/50\n",
      "45 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7547 - accuracy: 0.7240 - val_loss: 0.7029 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67544\n",
      "Epoch 47/50\n",
      "46 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7669 - accuracy: 0.7346 - val_loss: 0.4343 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67544\n",
      "Epoch 48/50\n",
      "47 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7518 - accuracy: 0.7282 - val_loss: 0.9662 - val_accuracy: 0.5789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67544\n",
      "Epoch 49/50\n",
      "48 1e-06\n",
      "95/95 [==============================] - 20s 207ms/step - loss: 0.7430 - accuracy: 0.7197 - val_loss: 2.7696 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67544\n",
      "Epoch 50/50\n",
      "49 1e-06\n",
      "95/95 [==============================] - 20s 206ms/step - loss: 0.7348 - accuracy: 0.7325 - val_loss: 0.7300 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67544\n"
     ]
    }
   ],
   "source": [
    "lr_best = 1e-3 # 还是肉眼手动根据绘图结果指定lr_best比较好一些，肉眼可以综合考虑学习率在训练时的稳定性\n",
    "\n",
    "if os.path.exists('Best_rock_Model(ResNet).h5'):\n",
    "    model_Best = 'Best_rock_Model(ResNet).h5'\n",
    "    model = load_model(model_Best)\n",
    "    optim = K.optimizers.Adam(lr=1e-4)\n",
    "else:\n",
    "    model = ResNet50Model()\n",
    "    optim = K.optimizers.Adam(lr=1e-4)#lr_best)\n",
    "\n",
    "# 定义学习率调整方案\n",
    "def scheduler(epoch):\n",
    "    lr = optim.lr.numpy()\n",
    "#     if epoch>=10:\n",
    "#         lr = 1e-4\n",
    "    if epoch>=3:\n",
    "        lr = 1e-6\n",
    "    print(epoch, lr)\n",
    "    return lr \n",
    "reduce_lr = K.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# 断点续训\n",
    "checkpoint = ModelCheckpoint('Best_rock_Model(ResNet).h5', verbose=1, monitor='val_accuracy', \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# 指定模型的损失函数，优化器，衡量指标\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 模型训练\n",
    "batch_size = 5\n",
    "history = model.fit(Generator(x_train, y_train, batch_size),\n",
    "              steps_per_epoch=len(x_train)//batch_size,\n",
    "              epochs=50,\n",
    "              validation_data=Generator(x_val, y_val, batch_size),\n",
    "              validation_steps=len(x_val) // batch_size,\n",
    "#               class_weight = 'auto',\n",
    "              callbacks=[checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练精度和验证精度\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, acc, label = 'Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('seed_520_acc.png',dpi=200) # 保存图片\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练损失和验证损失\n",
    "history_dict = history.history\n",
    "acc = history_dict['loss']\n",
    "val_accuracy = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, acc, label = 'Training loss')\n",
    "plt.plot(epochs, val_accuracy, label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('seed_520_loss.png',dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入图片,进行预测\n",
    "r = './rock/1-1.bmp'\n",
    "img = Image.open(r)\n",
    "img = img.resize((224,224))\n",
    "img = np.array(img)\n",
    "img = img[:,:,:3]\n",
    "img = imgsub(img)\n",
    "img = np.expand_dims(img,axis = 0 )\n",
    "\n",
    "\n",
    "if os.path.exists('Best_rock_Model(ResNet).h5'):\n",
    "    model_Best = 'Best_rock_Model(ResNet).h5'\n",
    "    model = load_model(model_Best)\n",
    "\n",
    "res = model.predict(img)\n",
    "\n",
    "# 预测结果\n",
    "print('Results are',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt绘图中显示中文和符号\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "df_label = pd.read_csv('label_new.csv')\n",
    "\n",
    "# fig = plt.figure(figsize = (15,4*315))\n",
    "for i in range(len(x_val)):\n",
    "    img_show_name = x_val[i]\n",
    "    img_show_num = os.path.split(img_show_name)[-1].split('-')[0]\n",
    "    img_show_num = int(img_show_num)\n",
    "    \n",
    "    # 利用样本编号（文件名,x_val）与样本类别的对应关系\n",
    "    label_show_chinese = df_label['样本类别'][df_label['样本编号']==img_show_num]\n",
    "    label_show_chinese = label_show_chinese.iloc[0]\n",
    "    \n",
    "    img = Image.open(img_show_name).convert('RGB')\n",
    "    img = img.resize((224,224))\n",
    "    img = np.array(img)\n",
    "    img_plot = img.copy()\n",
    "    \n",
    "    img = imgsub(img)\n",
    "    img = np.expand_dims(img,axis = 0 )\n",
    "    predict = model.predict(img)\n",
    "    predict_num = np.argmax(predict)\n",
    "    predict_chinese = df_label['样本类别'][df_label['类别标签']==predict_num].iloc[0]# 得到预测结果的中文\n",
    "    \n",
    "    #ax = fig.add_subplot(315,5,i+1)\n",
    "    if i%5==0:\n",
    "        plt.figure(figsize = (15,3))\n",
    "    plt.subplot(1,5,i%5+1)\n",
    "    img_plot = Image.fromarray(img_plot).resize((800,600))\n",
    "    img_plot = np.array(img_plot)\n",
    "    plt.imshow(img_plot)\n",
    "    plt.title(f'predict：{predict_chinese}\\nground truth：{label_show_chinese}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成器数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # 0.5的概率水平翻转\n",
    "    iaa.Crop(percent=(0, 0.2)), # random crops\n",
    "    #sigma在0~0.5间随机高斯模糊，且每张图纸生效的概率是0.5\n",
    "#     iaa.Sometimes(0.5,\n",
    "#         iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "#     ),\n",
    "    # 增大或减小每张图像的对比度\n",
    "    iaa.ContrastNormalization((0.9, 1.2)),\n",
    "    iaa.Multiply((1, 1.2), per_channel=0.2),\n",
    "    # 对每张图片进行仿射变换，包括缩放、平移、旋转、修剪等\n",
    "    iaa.Affine(\n",
    "#         scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True) # 随机应用以上的图片增强方法\n",
    "\n",
    "# 定义生成器，用于训练时batch的生成（小批量生成可以避免内存不够）\n",
    "def Generator(img_set,labels,batch_size):\n",
    "    while True:\n",
    "        img_batch = []\n",
    "        label_batch = []\n",
    "        for i in range(len(img_set)):\n",
    "            img_path = img_set[i]\n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((224,224))\n",
    "            img = np.asarray(img)\n",
    "#             img = imgsub(img)\n",
    "            img_batch.append(img)\n",
    "\n",
    "            label = labels[i]\n",
    "            label_batch.append(label)\n",
    "            if (i+1)%batch_size==0 or (i+1) == len(img_set):# 凑够batch_size张图片的矩阵\n",
    "                img_batch_before_aug = np.array(img_batch) # 拼成一个大矩阵，用于训练\n",
    "                img_batch = seq.augment_images(img_batch_before_aug.astype(np.uint8))\n",
    "#                 for i in range(img_batch.shape[0]):\n",
    "#                     img_batch[i] = imgsub(img_batch[i])\n",
    "                label_batch = np.array(label_batch)\n",
    "                label_batch = K.utils.to_categorical(label_batch, num_classes=7)\n",
    "                yield img_batch,label_batch,img_batch_before_aug\n",
    "\n",
    "                img_batch = []\n",
    "                label_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = Generator(x_train, y_train, batch_size)\n",
    "cnt = 0 \n",
    "for img_batch,label_batch,img_before in train_gen:\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_before[0])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_batch[0])\n",
    "    plt.show()\n",
    "    cnt+=1\n",
    "    if cnt==20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增强数据集本地保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # 0.5的概率水平翻转\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Crop(percent=(0, 0.2)), # random crops\n",
    "    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "    iaa.Multiply((0.75, 2)),\n",
    "    # 对每张图片进行仿射变换，包括缩放、平移、旋转、修剪等\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-180, 180),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True) # 随机应用以上的图片增强方法\n",
    "\n",
    "# 定义生成器，用于训练时batch的生成（小批量生成可以避免内存不够）\n",
    "def Generator(img_set,labels,batch_size,return_names = False):\n",
    "#     while True:\n",
    "    img_batch = []\n",
    "    label_batch = []\n",
    "    path_batch = []\n",
    "    for i in range(len(img_set)):\n",
    "        img_path = img_set[i]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((224,224))\n",
    "        img = np.asarray(img)\n",
    "        img_batch.append(img)\n",
    "\n",
    "        label = labels[i]\n",
    "        label_batch.append(label)\n",
    "        path_batch.append(img_path)\n",
    "        if (i+1)%batch_size==0 or (i+1) == len(img_set):# 凑够batch_size张图片的矩阵\n",
    "            img_batch = np.array(img_batch) # 拼成一个大矩阵，用于训练\n",
    "            img_batch = seq.augment_images(img_batch.astype(np.uint8)).astype(np.float64)\n",
    "#                 for i in range(img_batch.shape[0]):\n",
    "#                     img_batch[i] = imgsub(img_batch[i])\n",
    "            label_batch = np.array(label_batch)\n",
    "            label_batch = K.utils.to_categorical(label_batch, num_classes=7)\n",
    "            if not return_names:\n",
    "                yield img_batch,label_batch#,img_batch_before_aug\n",
    "            else:\n",
    "                yield img_batch,label_batch,path_batch\n",
    "            img_batch = []\n",
    "            label_batch = []\n",
    "            path_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('test_aug'):\n",
    "    os.mkdir('test_aug')\n",
    "if not os.path.exists('train_aug'):\n",
    "    os.mkdir('train_aug')\n",
    "    \n",
    "train_gen = Generator(x_train,y_train,5,return_names = True)\n",
    "cnt = 0\n",
    "for img_batch,label_batch,path_batch in train_gen:\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        label = np.argmax(label_batch[i])\n",
    "        img_path = os.path.join('train_aug',str(int(label)),os.path.split(path_batch[i])[-1].split('.')[0]+'_'+str(cnt)+'.png')\n",
    "        if not os.path.exists(os.path.split(img_path)[0]):\n",
    "            os.makedirs(os.path.split(img_path)[0])            \n",
    "        Image.fromarray(img_batch[i].astype(np.uint8)).save(img_path)\n",
    "        print(img_path,'is saved.')\n",
    "        cnt += 1\n",
    "#         if cnt==len(x_train):\n",
    "#             break\n",
    "        \n",
    "test_gen = Generator(x_val,y_val,5,return_names = True)\n",
    "cnt = 0\n",
    "for img_batch,label_batch,path_batch in test_gen:\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        label = np.argmax(label_batch[i])\n",
    "        img_path = os.path.join('test_aug',str(int(label)),os.path.split(path_batch[i])[-1].split('.')[0]+'_'+str(cnt)+'.png')\n",
    "        if not os.path.exists(os.path.split(img_path)[0]):\n",
    "            os.makedirs(os.path.split(img_path)[0])\n",
    "        Image.fromarray(img_batch[i].astype(np.uint8)).save(img_path)\n",
    "        print(img_path,'is saved.')\n",
    "        cnt += 1\n",
    "#         if cnt==len(x_val):\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
